# üí∞ Cost Calculation System Guide

**Status**: ‚úÖ **FULLY OPERATIONAL**  
**Last Updated**: January 2025  
**Version**: Production-ready with GenAI semantic convention support

---

## üéØ **Overview**

The cost calculation system tracks and aggregates LLM usage costs across workflow executions using industry-standard GenAI semantic conventions. This system provides accurate cost tracking for analytics, budgeting, and optimization.

---

## üèóÔ∏è **Architecture**

### **Cost Data Flow**
```
LLM API Call ‚îÄ‚îÄ‚ñ∫ GenAI Attributes ‚îÄ‚îÄ‚ñ∫ Span Storage ‚îÄ‚îÄ‚ñ∫ Cost Extraction ‚îÄ‚îÄ‚ñ∫ Analytics
     ‚îÇ                  ‚îÇ                   ‚îÇ                ‚îÇ              ‚îÇ
     ‚îî‚îÄ Token Usage     ‚îî‚îÄ Standard Format  ‚îî‚îÄ Trace Data    ‚îî‚îÄ Aggregation ‚îî‚îÄ Dashboard
```

### **Attribute Standards**
The system supports dual naming conventions for maximum compatibility:

#### **GenAI Semantic Convention (Primary)**
```json
{
  "gen_ai.usage.input_cost": 0.00017199999999999998,
  "gen_ai.usage.output_cost": 0.000776,
  "gen_ai.usage.input_tokens": 86,
  "gen_ai.usage.output_tokens": 97
}
```

#### **OpenInference Convention (Fallback)**
```json
{
  "cost_prompt": 0.000172,
  "cost_completion": 0.000776,
  "llm.token_count.prompt": 86,
  "llm.token_count.completion": 97
}
```

---

## üîß **Implementation Details**

### **1. Trace Processing (src/any_agent/tracing/trace.py)**

```python
def extract_token_use_and_cost(attributes):
    """Enhanced extraction supporting both conventions"""
    # Check GenAI format first (preferred)
    if "gen_ai.usage.input_cost" in attributes:
        return CostInfo(
            cost_prompt=float(attributes["gen_ai.usage.input_cost"]),
            cost_completion=float(attributes["gen_ai.usage.output_cost"])
        )
    
    # Fallback to OpenInference format
    elif "cost_prompt" in attributes:
        return CostInfo(
            cost_prompt=float(attributes["cost_prompt"]),
            cost_completion=float(attributes["cost_completion"])
        )
    
    # Calculate using LiteLLM as last resort
    else:
        cost_prompt, cost_completion = cost_per_token(
            model=attributes.get("gen_ai.request.model", ""),
            prompt_tokens=attributes.get("gen_ai.usage.input_tokens", 0),
            completion_tokens=attributes.get("gen_ai.usage.output_tokens", 0)
        )
        return CostInfo(cost_prompt=cost_prompt, cost_completion=cost_completion)
```

### **2. Backend Cost Extraction (backend/main.py)**

```python
def _extract_cost_info_from_trace(self, agent_trace):
    """Extract cost information from trace data using GenAI semantic convention"""
    if isinstance(agent_trace, dict):
        spans = agent_trace.get("spans", [])
        total_cost = 0.0
        total_tokens = 0
        input_tokens = 0
        output_tokens = 0
        
        for span in spans:
            attributes = span.get("attributes", {})
            
            # Extract costs from GenAI semantic convention attributes
            input_cost = attributes.get("gen_ai.usage.input_cost", 0.0)
            output_cost = attributes.get("gen_ai.usage.output_cost", 0.0)
            
            # Extract token counts
            span_input_tokens = attributes.get("gen_ai.usage.input_tokens", 0)
            span_output_tokens = attributes.get("gen_ai.usage.output_tokens", 0)
            
            total_cost += float(input_cost) + float(output_cost)
            input_tokens += int(span_input_tokens)
            output_tokens += int(span_output_tokens)
            total_tokens += int(span_input_tokens) + int(span_output_tokens)
        
        return {
            "total_cost": total_cost,
            "total_tokens": total_tokens,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens
        }
```

### **3. Analytics Aggregation**

```python
# Workflow-level cost aggregation
group_cost = sum(
    e.get("trace", {}).get("cost_info", {}).get("total_cost", 0) 
    for e in completed_in_group
)

# Performance overview calculation  
total_cost = sum(
    e.get("trace", {}).get("cost_info", {}).get("total_cost", 0) 
    for e in completed_executions
)
avg_cost = total_cost / len(completed_executions) if completed_executions else 0
```

---

## üìä **Data Examples**

### **Typical Cost Values**
```json
{
  "execution_id": "exec_4",
  "cost_info": {
    "total_cost": 0.000948,      // ~$0.0009 per execution
    "total_tokens": 183,         // Input + output tokens
    "input_tokens": 86,          // Prompt tokens
    "output_tokens": 97          // Completion tokens
  }
}
```

### **Analytics Dashboard Format**
```json
{
  "performance_overview": {
    "total_cost": 0.002844,           // Sum across all executions
    "average_cost_per_execution": 0.000948,  // Average cost
    "total_executions": 3
  },
  "all_workflows": [
    {
      "workflow_name": "Grizzly Bear Viewing Guide",
      "total_cost": 0.000948,
      "average_cost": 0.000948,
      "total_executions": 1
    }
  ]
}
```

---

## üîç **Troubleshooting**

### **Common Issues**

#### **1. Costs Show as $0.0000**
**Symptoms**: Analytics dashboard shows zero costs despite successful executions
**Cause**: Cost extraction not finding GenAI attributes
**Solution**: Check span attributes format and ensure GenAI convention compliance

#### **2. Missing Cost Data**
**Symptoms**: `cost_info` field is empty `{}`
**Solution**: Verify LLM API is providing cost information in traces

#### **3. Cache Issues in Production**
**Symptoms**: Stale cost data in analytics
**Solution**: Cache-busting headers are implemented - clear browser cache

### **Debugging Commands**

```bash
# Check raw trace data
curl "https://agentbuilder-9q23.onrender.com/executions/exec_4/trace" | jq '.trace.spans[0].attributes'

# Check analytics aggregation
curl "https://agentbuilder-9q23.onrender.com/analytics/workflows" | jq '.performance_overview'

# Verify cost extraction logic locally
python3 -c "
spans = [{'attributes': {'gen_ai.usage.input_cost': 0.000172, 'gen_ai.usage.output_cost': 0.000776}}]
total = sum(float(s['attributes']['gen_ai.usage.input_cost']) + float(s['attributes']['gen_ai.usage.output_cost']) for s in spans)
print(f'Total cost: ${total:.6f}')
"
```

---

## üöÄ **Production Deployment**

### **Vercel Frontend Configuration**
```typescript
// frontend/app/api/analytics/workflows/route.ts
const BACKEND_URL = process.env.BACKEND_URL || 'http://localhost:8000'

const backendResponse = await fetch(`${BACKEND_URL}/analytics/workflows?_t=${Date.now()}`, {
  headers: {
    'Cache-Control': 'no-cache, no-store, must-revalidate',
    'Pragma': 'no-cache',
  },
  cache: 'no-store'
})
```

### **Render Backend Configuration**
```python
# backend/main.py - Cost extraction
def _extract_cost_info_from_trace(self, agent_trace):
    # Production-ready GenAI semantic convention support
    # Handles both dictionary traces and AgentTrace objects
    # Aggregates costs across all spans
```

### **Environment Variables**
```bash
# Frontend (Vercel)
BACKEND_URL=https://agentbuilder-9q23.onrender.com

# Backend (Render)  
OPENAI_API_KEY=your_openai_key
RENDER=true
```

---

## üìà **Performance Characteristics**

### **Cost Magnitude Examples**
- **Simple Q&A**: ~$0.0001 - $0.001
- **Research Workflow**: ~$0.002 - $0.01  
- **Multi-agent Complex**: ~$0.01 - $0.05

### **Token Usage Patterns**
- **GPT-4o Mini**: ~$0.000003/1K input, $0.000012/1K output
- **GPT-4o**: ~$0.000005/1K input, $0.000015/1K output

### **Aggregation Performance**
- **Span Processing**: O(n) where n = number of spans
- **Analytics Aggregation**: O(m) where m = number of executions
- **Real-time Updates**: < 100ms for typical workloads

---

## ‚úÖ **Verification Checklist**

- [ ] GenAI semantic convention attributes present in traces
- [ ] Cost extraction returns non-zero values for actual executions
- [ ] Analytics dashboard shows accurate cost totals
- [ ] Individual execution costs match span aggregation
- [ ] Production backend properly configured
- [ ] Cache-busting prevents stale data
- [ ] Both naming conventions supported for compatibility

---

## üîó **Related Documentation**

- [IMPLEMENTATION_SUMMARY.md](./IMPLEMENTATION_SUMMARY.md) - Overall system architecture
- [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md) - Production deployment
- [src/any_agent/tracing/trace.py](./src/any_agent/tracing/trace.py) - Core trace processing
- [backend/main.py](./backend/main.py) - Backend cost extraction

---

**Last Fix**: January 2025 - Complete rewrite of cost extraction to support GenAI semantic convention with backward compatibility for OpenInference format. 