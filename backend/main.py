#!/usr/bin/env python3
"""
any-agent Workflow Composer Backend

FastAPI server that bridges the Next.js frontend with the any-agent Python framework.
Provides endpoints for:
- Creating and managing agents
- Executing workflows
- Real-time execution status
- Agent trace retrieval
"""

import asyncio
import concurrent.futures
import os
import sys
import time
from contextlib import asynccontextmanager
from typing import Any, Dict, List, Optional

import uvicorn
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel

# Load environment variables from .env file
from setup_env import setup_environment

# Setup environment and get configuration
config = setup_environment()

# Import any-agent framework
from any_agent import AgentConfig, AgentFramework, AnyAgent
from any_agent.tools import search_web

# Import our NEW visual-to-anyagent translator (replacing custom workflow engine)
from visual_to_anyagent_translator import execute_visual_workflow_with_anyagent


class WorkflowNode(BaseModel):
    """Represents a node in the visual workflow"""
    id: str
    type: str  # 'agent', 'tool', 'input', 'output'
    data: Dict[str, Any]
    position: Dict[str, float]


class WorkflowEdge(BaseModel):
    """Represents an edge (connection) between nodes"""
    id: str
    source: str
    target: str


class WorkflowDefinition(BaseModel):
    """Complete workflow definition from the frontend"""
    nodes: List[WorkflowNode]
    edges: List[WorkflowEdge]


class ExecutionRequest(BaseModel):
    """Request to execute a workflow"""
    workflow: WorkflowDefinition
    input_data: str
    framework: str = "openai"  # Default to OpenAI


class ExecutionResponse(BaseModel):
    """Response from workflow execution"""
    execution_id: str
    status: str
    result: Optional[str] = None
    trace: Optional[Dict[str, Any]] = None
    error: Optional[str] = None


class WorkflowExecutor:
    """Execute workflows using any-agent's native multi-agent orchestration"""
    
    def __init__(self):
        self.executions: Dict[str, Dict[str, Any]] = {}

    async def execute_workflow(self, request: ExecutionRequest) -> ExecutionResponse:
        """Execute a workflow definition using any-agent's native multi-agent capabilities"""
        execution_id = f"exec_{len(self.executions) + 1}"
        start_time = time.time()
        
        try:
            # Initialize execution record with timestamp
            self.executions[execution_id] = {
                "status": "running",
                "input": request.input_data,
                "created_at": start_time,
                "workflow": request.workflow,
                "framework": request.framework
            }
            
            # Convert workflow to format expected by translator
            nodes = [
                {
                    "id": node.id,
                    "type": node.type,
                    "data": node.data,
                    "position": node.position
                }
                for node in request.workflow.nodes
            ]
            
            edges = [
                {
                    "id": edge.id,
                    "source": edge.source,
                    "target": edge.target
                }
                for edge in request.workflow.edges
            ]
            
            # Execute using any-agent's native multi-agent orchestration
            workflow_result = await execute_visual_workflow_with_anyagent(
                nodes=nodes,
                edges=edges,
                input_data=request.input_data,
                framework=request.framework
            )
            
            # Store execution details with completion timestamp
            completion_time = time.time()
            
            # Check if there was an error
            if "error" in workflow_result:
                self.executions[execution_id].update({
                    "status": "failed",
                    "result": workflow_result["final_output"],
                    "error": workflow_result["error"],
                    "completed_at": completion_time,
                    "execution_time": completion_time - start_time,
                    "trace": {
                        "error": workflow_result["error"],
                        "framework_used": request.framework
                    }
                })
                
                return ExecutionResponse(
                    execution_id=execution_id,
                    status="failed",
                    error=workflow_result["error"],
                    trace=self.executions[execution_id]["trace"]
                )
            
            # Success case
            self.executions[execution_id].update({
                "status": "completed",
                "result": workflow_result["final_output"],
                "completed_at": completion_time,
                "execution_time": completion_time - start_time,
                "trace": {
                    "final_output": workflow_result["final_output"],
                    "execution_pattern": workflow_result["execution_pattern"],
                    "main_agent": workflow_result["main_agent"],
                    "managed_agents": workflow_result["managed_agents"],
                    "framework_used": workflow_result["framework_used"],
                    "agent_trace": self._serialize_agent_trace(workflow_result.get("agent_trace")),
                    "execution_time": completion_time - start_time,
                    "cost_info": self._extract_cost_info_from_trace(workflow_result.get("agent_trace")),
                    "performance": self._extract_performance_metrics(workflow_result.get("agent_trace"), completion_time - start_time),
                    "spans": self._extract_spans_from_trace(workflow_result.get("agent_trace"))
                }
            })
            
            return ExecutionResponse(
                execution_id=execution_id,
                status="completed",
                result=workflow_result["final_output"],
                trace=self.executions[execution_id]["trace"]
            )
            
        except Exception as e:
            completion_time = time.time()
            self.executions[execution_id].update({
                "status": "failed",
                "error": str(e),
                "completed_at": completion_time,
                "execution_time": completion_time - start_time
            })
            
            return ExecutionResponse(
                execution_id=execution_id,
                status="failed",
                error=str(e)
            )
    
    def _serialize_agent_trace(self, agent_trace) -> Dict[str, Any]:
        """Serialize any-agent's AgentTrace object for storage/transmission"""
        if not agent_trace:
            return {}
        
        try:
            # If agent_trace is already a dictionary (from our new extraction), use it directly
            if isinstance(agent_trace, dict):
                return agent_trace
            
            # Legacy handling for raw agent trace objects
            return {
                "final_output": getattr(agent_trace, 'final_output', ''),
                "spans": [self._serialize_span(span) for span in getattr(agent_trace, 'spans', [])],
                "cost_info": self._extract_cost_info(agent_trace),
                "metadata": {
                    "total_spans": len(getattr(agent_trace, 'spans', [])),
                    "has_cost_info": hasattr(agent_trace, 'get_total_cost')
                }
            }
        except Exception as e:
            return {"serialization_error": str(e)}
    
    def _serialize_span(self, span) -> Dict[str, Any]:
        """Serialize individual span from any-agent trace"""
        try:
            return {
                "name": getattr(span, 'name', ''),
                "kind": str(getattr(span, 'kind', '')),
                "start_time": getattr(span, 'start_time', 0),
                "end_time": getattr(span, 'end_time', 0),
                "attributes": dict(getattr(span, 'attributes', {})),
                "status": str(getattr(span, 'status', '')),
                "events": [str(event) for event in getattr(span, 'events', [])]
            }
        except Exception as e:
            return {"span_error": str(e)}
    
    def _extract_cost_info(self, agent_trace) -> Dict[str, Any]:
        """Extract cost information from any-agent trace"""
        if not agent_trace or not hasattr(agent_trace, 'get_total_cost'):
            return {}
        
        try:
            cost_info = agent_trace.get_total_cost()
            return {
                "total_cost": getattr(cost_info, 'total_cost', 0),
                "total_tokens": getattr(cost_info, 'total_tokens', 0),
                "input_tokens": getattr(cost_info, 'input_tokens', 0),
                "output_tokens": getattr(cost_info, 'output_tokens', 0)
            }
        except Exception as e:
            return {"cost_extraction_error": str(e)}
    
    def _extract_cost_info_from_trace(self, agent_trace) -> Dict[str, Any]:
        """Extract cost information from the new trace data structure"""
        if not agent_trace:
            return {}
        
        try:
            # If it's our new dictionary structure
            if isinstance(agent_trace, dict):
                return agent_trace.get("cost_info", {})
            
            # Fallback to legacy method
            return self._extract_cost_info(agent_trace)
        except Exception as e:
            return {"cost_extraction_error": str(e)}
    
    def _extract_performance_metrics(self, agent_trace, execution_time: float) -> Dict[str, Any]:
        """Extract performance metrics from trace data"""
        if not agent_trace:
            return {"total_duration_ms": execution_time * 1000}
        
        try:
            # If it's our new dictionary structure
            if isinstance(agent_trace, dict):
                performance = agent_trace.get("performance", {})
                # Ensure we have execution time
                performance["total_duration_ms"] = performance.get("total_duration_ms", execution_time * 1000)
                return performance
            
            # Legacy fallback
            return {"total_duration_ms": execution_time * 1000}
        except Exception as e:
            return {"performance_extraction_error": str(e), "total_duration_ms": execution_time * 1000}
    
    def _extract_spans_from_trace(self, agent_trace) -> List[Dict[str, Any]]:
        """Extract spans from trace data"""
        if not agent_trace:
            return []
        
        try:
            # If it's our new dictionary structure
            if isinstance(agent_trace, dict):
                return agent_trace.get("spans", [])
            
            # Legacy fallback
            if hasattr(agent_trace, 'spans'):
                return [self._serialize_span(span) for span in getattr(agent_trace, 'spans', [])]
            
            return []
        except Exception as e:
            return []


# Global executor instance
executor = WorkflowExecutor()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan management"""
    print("🚀 any-agent Workflow Composer Backend starting...")
    yield
    print("🛑 any-agent Workflow Composer Backend shutting down...")


# Create FastAPI app
app = FastAPI(
    title="any-agent Workflow Composer Backend",
    description="Bridge between Next.js frontend and any-agent framework",
    version="1.0.0",
    lifespan=lifespan
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],  # Next.js dev servers
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
async def root():
    """Health check endpoint"""
    return {"message": "any-agent Workflow Composer Backend", "status": "running"}


@app.get("/frameworks")
async def list_frameworks():
    """List available agent frameworks"""
    return {
        "frameworks": [framework.name for framework in AgentFramework],
        "default": AgentFramework.OPENAI.name
    }


@app.post("/execute", response_model=ExecutionResponse)
async def execute_workflow(request: ExecutionRequest):
    """Execute a workflow using any-agent"""
    return await executor.execute_workflow(request)


@app.get("/executions/{execution_id}")
async def get_execution(execution_id: str):
    """Get execution details by ID"""
    if execution_id not in executor.executions:
        raise HTTPException(status_code=404, detail="Execution not found")
    
    return executor.executions[execution_id]


@app.get("/executions/{execution_id}/trace")
async def get_execution_trace(execution_id: str):
    """Get detailed trace information for an execution"""
    if execution_id not in executor.executions:
        raise HTTPException(status_code=404, detail="Execution not found")
    
    execution = executor.executions[execution_id]
    if "trace" not in execution:
        raise HTTPException(status_code=404, detail="Trace not found for this execution")
    
    # Return the full trace data with all spans and performance metrics
    return {
        "execution_id": execution_id,
        "status": execution["status"],
        "trace": execution["trace"],
        "created_at": execution.get("created_at", None)
    }


@app.get("/executions/{execution_id}/performance")
async def get_execution_performance(execution_id: str):
    """Get performance metrics for an execution"""
    if execution_id not in executor.executions:
        raise HTTPException(status_code=404, detail="Execution not found")
    
    execution = executor.executions[execution_id]
    if "trace" not in execution:
        raise HTTPException(status_code=404, detail="Performance data not available")
    
    trace_data = execution["trace"]
    performance = trace_data.get("performance", {})
    spans = trace_data.get("spans", [])
    
    # Enhanced performance analysis
    span_analysis = []
    for span in spans:
        span_perf = {
            "name": span.get("name"),
            "duration_ms": span.get("duration_ms"),
            "token_usage": {
                "prompt": span.get("attributes", {}).get("llm.token_count.prompt", 0),
                "completion": span.get("attributes", {}).get("llm.token_count.completion", 0)
            },
            "cost": {
                "prompt": span.get("attributes", {}).get("cost_prompt", 0),
                "completion": span.get("attributes", {}).get("cost_completion", 0)
            },
            "model": span.get("attributes", {}).get("llm.model_name", "unknown")
        }
        span_analysis.append(span_perf)
    
    return {
        "execution_id": execution_id,
        "overall_performance": performance,
        "span_breakdown": span_analysis,
        "bottlenecks": sorted(span_analysis, key=lambda x: x.get("duration_ms", 0), reverse=True)[:3],
        "cost_breakdown": {
            "most_expensive_spans": sorted(span_analysis, 
                key=lambda x: x.get("cost", {}).get("prompt", 0) + x.get("cost", {}).get("completion", 0), 
                reverse=True)[:3]
        }
    }


@app.get("/analytics/executions")
async def get_execution_analytics():
    """Get aggregated analytics across all executions"""
    if not executor.executions:
        return {"message": "No executions found", "analytics": {}}
    
    executions = list(executor.executions.values())
    completed_executions = [e for e in executions if e.get("status") == "completed" and "trace" in e]
    
    if not completed_executions:
        return {"message": "No completed executions with traces found", "analytics": {}}
    
    # Aggregate performance data
    total_cost = 0
    total_tokens = 0
    total_duration = 0
    model_usage = {}
    
    for execution in completed_executions:
        trace = execution.get("trace", {})
        performance = trace.get("performance", {})
        
        total_cost += performance.get("total_cost", 0)
        total_tokens += performance.get("total_tokens", 0)
        total_duration += performance.get("total_duration_ms", 0)
        
        # Track model usage
        for span in trace.get("spans", []):
            model = span.get("attributes", {}).get("llm.model_name", "unknown")
            if model not in model_usage:
                model_usage[model] = {"count": 0, "total_cost": 0, "total_tokens": 0}
            model_usage[model]["count"] += 1
            model_usage[model]["total_cost"] += span.get("attributes", {}).get("cost_prompt", 0) + span.get("attributes", {}).get("cost_completion", 0)
            model_usage[model]["total_tokens"] += span.get("attributes", {}).get("llm.token_count.prompt", 0) + span.get("attributes", {}).get("llm.token_count.completion", 0)
    
    avg_cost = total_cost / len(completed_executions) if completed_executions else 0
    avg_duration = total_duration / len(completed_executions) if completed_executions else 0
    
    return {
        "summary": {
            "total_executions": len(executor.executions),
            "completed_executions": len(completed_executions),
            "total_cost": round(total_cost, 4),
            "total_tokens": total_tokens,
            "total_duration_ms": total_duration,
            "average_cost_per_execution": round(avg_cost, 4),
            "average_duration_per_execution": round(avg_duration, 2)
        },
        "model_breakdown": model_usage,
        "recent_executions": [
            {
                "execution_id": exec_id,
                "status": execution["status"],
                "cost": execution.get("trace", {}).get("performance", {}).get("total_cost", 0),
                "duration_ms": execution.get("trace", {}).get("performance", {}).get("total_duration_ms", 0)
            }
            for exec_id, execution in list(executor.executions.items())[-10:]  # Last 10 executions
        ]
    }


@app.websocket("/ws/execution/{execution_id}")
async def websocket_execution_status(websocket: WebSocket, execution_id: str):
    """WebSocket endpoint for real-time execution updates"""
    await websocket.accept()
    
    try:
        while True:
            if execution_id in executor.executions:
                execution = executor.executions[execution_id]
                await websocket.send_json(execution)
                
                if execution.get("status") in ["completed", "failed"]:
                    break
            
            await asyncio.sleep(1)  # Poll every second
            
    except WebSocketDisconnect:
        print(f"WebSocket disconnected for execution {execution_id}")


if __name__ == "__main__":
    # Check for required environment variables
    if not os.getenv("OPENAI_API_KEY"):
        print("⚠️  Warning: OPENAI_API_KEY not set. OpenAI agents will not work.")
        print("🔧 Please set your OpenAI API key: export OPENAI_API_KEY='your_key_here'")
    
    print("🔥 Starting any-agent Workflow Composer Backend...")
    print("📡 Backend will be available at: http://localhost:8000")
    print("📖 API docs will be available at: http://localhost:8000/docs")
    
    execution_mode = os.getenv("USE_MOCK_EXECUTION", "false").lower()
    if execution_mode == "true":
        print("📝 Running in WORKFLOW SUGGESTION MODE")
        print("   - Provides intelligent workflow building guidance") 
        print("   - No asyncio conflicts")
    else:
        print("🤖 Running in REAL EXECUTION MODE with AsyncIO Conflict Resolution")
        print("   - Process isolation: ✅ any-agent runs in separate processes")
        print("   - Thread fallback: ✅ isolated event loops as backup")
        print("   - Suggestion fallback: ✅ graceful degradation if needed")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 